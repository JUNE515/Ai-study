{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu39oBW0RVn5"
   },
   "source": [
    "# [과제 3] 로지스틱 회귀분석\n",
    "### - sklearn 패키지를 사용해 로지스틱 회귀분석을 진행해주세요.\n",
    "### - 성능지표를 계산하고 이에 대해 해석해주세요.\n",
    "### - 성능 개선을 시도해주세요. (어떠한 성능지표를 기준으로 개선을 시도했는지, 그 이유도 함께 적어주세요.)\n",
    "### - 주석으로 설명 및 근거 자세하게 달아주시면 감사하겠습니다. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rN2SWezRVn_"
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7SYKNvQRVn_"
   },
   "source": [
    "출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "* V1 ~ V28 : 비식별화 된 개인정보 \n",
    "* **Class** : Target 변수  \n",
    "  - 1 : fraudulent transactions (사기)\n",
    "  - 0 : otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Uvjw2fTCRVoA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "znQit70ZRVoA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"assignment3_creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "v98OeXW5RVoB",
    "outputId": "42afeddc-07e6-4224-95ee-08b455f72475"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.848212</td>\n",
       "      <td>2.384900</td>\n",
       "      <td>0.379573</td>\n",
       "      <td>1.048381</td>\n",
       "      <td>-0.845070</td>\n",
       "      <td>2.537837</td>\n",
       "      <td>-4.542983</td>\n",
       "      <td>-10.201458</td>\n",
       "      <td>-1.504967</td>\n",
       "      <td>-2.234167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585817</td>\n",
       "      <td>-5.291690</td>\n",
       "      <td>0.859364</td>\n",
       "      <td>0.423231</td>\n",
       "      <td>-0.506985</td>\n",
       "      <td>1.020052</td>\n",
       "      <td>-0.627751</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.071805</td>\n",
       "      <td>-0.477943</td>\n",
       "      <td>-1.444444</td>\n",
       "      <td>-0.548657</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>-0.582242</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>-0.247160</td>\n",
       "      <td>1.171923</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077306</td>\n",
       "      <td>0.042858</td>\n",
       "      <td>0.390125</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>0.598427</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>0.979686</td>\n",
       "      <td>-0.093244</td>\n",
       "      <td>-0.065615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.985294</td>\n",
       "      <td>-2.747472</td>\n",
       "      <td>1.194068</td>\n",
       "      <td>-0.003036</td>\n",
       "      <td>-1.151041</td>\n",
       "      <td>-0.263559</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.438545</td>\n",
       "      <td>-1.806488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.345776</td>\n",
       "      <td>0.373760</td>\n",
       "      <td>-0.385777</td>\n",
       "      <td>1.197596</td>\n",
       "      <td>0.407229</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.762362</td>\n",
       "      <td>-0.299024</td>\n",
       "      <td>-0.303929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.479452</td>\n",
       "      <td>1.542874</td>\n",
       "      <td>0.290895</td>\n",
       "      <td>0.838142</td>\n",
       "      <td>-0.529290</td>\n",
       "      <td>-0.717661</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>-0.780767</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.116771</td>\n",
       "      <td>0.405560</td>\n",
       "      <td>-0.116453</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>-0.216665</td>\n",
       "      <td>-0.415578</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>-0.150347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281976</td>\n",
       "      <td>-0.309699</td>\n",
       "      <td>-2.162299</td>\n",
       "      <td>-0.851514</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>-1.483888</td>\n",
       "      <td>1.930994</td>\n",
       "      <td>-0.843049</td>\n",
       "      <td>-1.249272</td>\n",
       "      <td>1.079608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.875516</td>\n",
       "      <td>-0.004199</td>\n",
       "      <td>1.015108</td>\n",
       "      <td>-0.026748</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>-1.468822</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.496732</td>\n",
       "      <td>0.331001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7   \n",
       "0 -1.848212  2.384900  0.379573  1.048381 -0.845070  2.537837 -4.542983  \\\n",
       "1  2.071805 -0.477943 -1.444444 -0.548657  0.010036 -0.582242 -0.042878   \n",
       "2 -2.985294 -2.747472  1.194068 -0.003036 -1.151041 -0.263559  0.553500   \n",
       "3 -1.479452  1.542874  0.290895  0.838142 -0.529290 -0.717661  0.484516   \n",
       "4 -0.281976 -0.309699 -2.162299 -0.851514  0.106167 -1.483888  1.930994   \n",
       "\n",
       "          V8        V9       V10  ...       V20       V21       V22       V23   \n",
       "0 -10.201458 -1.504967 -2.234167  ...  2.585817 -5.291690  0.859364  0.423231  \\\n",
       "1  -0.247160  1.171923 -0.342382  ... -0.077306  0.042858  0.390125  0.041569   \n",
       "2   0.635600  0.438545 -1.806488  ...  1.345776  0.373760 -0.385777  1.197596   \n",
       "3   0.545092 -0.780767  0.324804  ...  0.038397  0.116771  0.405560 -0.116453   \n",
       "4  -0.843049 -1.249272  1.079608  ... -0.875516 -0.004199  1.015108 -0.026748   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0 -0.506985  1.020052 -0.627751 -0.017753  0.280982      0  \n",
       "1  0.598427  0.098803  0.979686 -0.093244 -0.065615      0  \n",
       "2  0.407229  0.008013  0.762362 -0.299024 -0.303929      0  \n",
       "3  0.541275 -0.216665 -0.415578  0.027126 -0.150347      0  \n",
       "4  0.077115 -1.468822  0.751700  0.496732  0.331001      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Class\"], axis=1)\n",
    "y = data.Class\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979426738266267"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.640</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.639</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1816.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Aug 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:42:17</td>     <th>  Log-Likelihood:    </th>  <td>  42301.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 28678</td>      <th>  AIC:               </th> <td>-8.454e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 28649</td>      <th>  BIC:               </th> <td>-8.430e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0041</td> <td>    0.000</td> <td>   12.401</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0022</td> <td>    0.000</td> <td>  -13.127</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0025</td> <td>    0.000</td> <td>   11.510</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0061</td> <td>    0.000</td> <td>  -29.568</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0064</td> <td>    0.000</td> <td>   27.858</td> <td> 0.000</td> <td>    0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0015</td> <td>    0.000</td> <td>   -6.325</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0021</td> <td>    0.000</td> <td>   -8.466</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0048</td> <td>    0.000</td> <td>  -19.194</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -2.005</td> <td> 0.045</td> <td>   -0.001</td> <td>-1.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0040</td> <td>    0.000</td> <td>  -13.618</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0090</td> <td>    0.000</td> <td>  -30.872</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0085</td> <td>    0.000</td> <td>   27.023</td> <td> 0.000</td> <td>    0.008</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0136</td> <td>    0.000</td> <td>  -44.229</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0009</td> <td>    0.000</td> <td>   -2.618</td> <td> 0.009</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0212</td> <td>    0.000</td> <td>  -68.192</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> 7.813e-06</td> <td>    0.000</td> <td>    0.022</td> <td> 0.983</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0094</td> <td>    0.000</td> <td>  -25.967</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0138</td> <td>    0.000</td> <td>  -41.248</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0033</td> <td>    0.000</td> <td>   -8.686</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0012</td> <td>    0.000</td> <td>    3.014</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0005</td> <td>    0.000</td> <td>    1.159</td> <td> 0.246</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0056</td> <td>    0.000</td> <td>   14.058</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0006</td> <td>    0.000</td> <td>   -1.239</td> <td> 0.216</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0006</td> <td>    0.001</td> <td>   -1.102</td> <td> 0.270</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0013</td> <td>    0.001</td> <td>   -2.362</td> <td> 0.018</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.0008</td> <td>    0.001</td> <td>    1.333</td> <td> 0.183</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0004</td> <td>    0.001</td> <td>    0.568</td> <td> 0.570</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.0023</td> <td>    0.001</td> <td>    2.757</td> <td> 0.006</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.0092</td> <td>    0.001</td> <td>    8.215</td> <td> 0.000</td> <td>    0.007</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45912.249</td> <th>  Durbin-Watson:     </th>   <td>   2.008</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>45900397.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.323</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>197.902</td>  <th>  Cond. No.          </th>   <td>    8.90</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &      0.640    \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.639    \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      1816.    \\\\\n",
       "\\textbf{Date:}             & Wed, 02 Aug 2023 & \\textbf{  Prob (F-statistic):} &      0.00     \\\\\n",
       "\\textbf{Time:}             &     16:42:17     & \\textbf{  Log-Likelihood:    } &     42301.    \\\\\n",
       "\\textbf{No. Observations:} &       28678      & \\textbf{  AIC:               } &  -8.454e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &       28649      & \\textbf{  BIC:               } &  -8.430e+04   \\\\\n",
       "\\textbf{Df Model:}         &          28      & \\textbf{                     } &               \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &               \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.0041  &        0.000     &    12.401  &         0.000        &        0.003    &        0.005     \\\\\n",
       "\\textbf{x1}    &      -0.0022  &        0.000     &   -13.127  &         0.000        &       -0.003    &       -0.002     \\\\\n",
       "\\textbf{x2}    &       0.0025  &        0.000     &    11.510  &         0.000        &        0.002    &        0.003     \\\\\n",
       "\\textbf{x3}    &      -0.0061  &        0.000     &   -29.568  &         0.000        &       -0.006    &       -0.006     \\\\\n",
       "\\textbf{x4}    &       0.0064  &        0.000     &    27.858  &         0.000        &        0.006    &        0.007     \\\\\n",
       "\\textbf{x5}    &      -0.0015  &        0.000     &    -6.325  &         0.000        &       -0.002    &       -0.001     \\\\\n",
       "\\textbf{x6}    &      -0.0021  &        0.000     &    -8.466  &         0.000        &       -0.003    &       -0.002     \\\\\n",
       "\\textbf{x7}    &      -0.0048  &        0.000     &   -19.194  &         0.000        &       -0.005    &       -0.004     \\\\\n",
       "\\textbf{x8}    &      -0.0005  &        0.000     &    -2.005  &         0.045        &       -0.001    &    -1.08e-05     \\\\\n",
       "\\textbf{x9}    &      -0.0040  &        0.000     &   -13.618  &         0.000        &       -0.005    &       -0.003     \\\\\n",
       "\\textbf{x10}   &      -0.0090  &        0.000     &   -30.872  &         0.000        &       -0.010    &       -0.008     \\\\\n",
       "\\textbf{x11}   &       0.0085  &        0.000     &    27.023  &         0.000        &        0.008    &        0.009     \\\\\n",
       "\\textbf{x12}   &      -0.0136  &        0.000     &   -44.229  &         0.000        &       -0.014    &       -0.013     \\\\\n",
       "\\textbf{x13}   &      -0.0009  &        0.000     &    -2.618  &         0.009        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{x14}   &      -0.0212  &        0.000     &   -68.192  &         0.000        &       -0.022    &       -0.021     \\\\\n",
       "\\textbf{x15}   &    7.813e-06  &        0.000     &     0.022  &         0.983        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{x16}   &      -0.0094  &        0.000     &   -25.967  &         0.000        &       -0.010    &       -0.009     \\\\\n",
       "\\textbf{x17}   &      -0.0138  &        0.000     &   -41.248  &         0.000        &       -0.014    &       -0.013     \\\\\n",
       "\\textbf{x18}   &      -0.0033  &        0.000     &    -8.686  &         0.000        &       -0.004    &       -0.003     \\\\\n",
       "\\textbf{x19}   &       0.0012  &        0.000     &     3.014  &         0.003        &        0.000    &        0.002     \\\\\n",
       "\\textbf{x20}   &       0.0005  &        0.000     &     1.159  &         0.246        &       -0.000    &        0.001     \\\\\n",
       "\\textbf{x21}   &       0.0056  &        0.000     &    14.058  &         0.000        &        0.005    &        0.006     \\\\\n",
       "\\textbf{x22}   &      -0.0006  &        0.000     &    -1.239  &         0.216        &       -0.001    &        0.000     \\\\\n",
       "\\textbf{x23}   &      -0.0006  &        0.001     &    -1.102  &         0.270        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{x24}   &      -0.0013  &        0.001     &    -2.362  &         0.018        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{x25}   &       0.0008  &        0.001     &     1.333  &         0.183        &       -0.000    &        0.002     \\\\\n",
       "\\textbf{x26}   &       0.0004  &        0.001     &     0.568  &         0.570        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{x27}   &       0.0023  &        0.001     &     2.757  &         0.006        &        0.001    &        0.004     \\\\\n",
       "\\textbf{x28}   &       0.0092  &        0.001     &     8.215  &         0.000        &        0.007    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 45912.249 & \\textbf{  Durbin-Watson:     } &      2.008    \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 45900397.366  \\\\\n",
       "\\textbf{Skew:}          &   10.323  & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
       "\\textbf{Kurtosis:}      &  197.902  & \\textbf{  Cond. No.          } &       8.90    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.640\n",
       "Model:                            OLS   Adj. R-squared:                  0.639\n",
       "Method:                 Least Squares   F-statistic:                     1816.\n",
       "Date:                Wed, 02 Aug 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:42:17   Log-Likelihood:                 42301.\n",
       "No. Observations:               28678   AIC:                        -8.454e+04\n",
       "Df Residuals:                   28649   BIC:                        -8.430e+04\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0041      0.000     12.401      0.000       0.003       0.005\n",
       "x1            -0.0022      0.000    -13.127      0.000      -0.003      -0.002\n",
       "x2             0.0025      0.000     11.510      0.000       0.002       0.003\n",
       "x3            -0.0061      0.000    -29.568      0.000      -0.006      -0.006\n",
       "x4             0.0064      0.000     27.858      0.000       0.006       0.007\n",
       "x5            -0.0015      0.000     -6.325      0.000      -0.002      -0.001\n",
       "x6            -0.0021      0.000     -8.466      0.000      -0.003      -0.002\n",
       "x7            -0.0048      0.000    -19.194      0.000      -0.005      -0.004\n",
       "x8            -0.0005      0.000     -2.005      0.045      -0.001   -1.08e-05\n",
       "x9            -0.0040      0.000    -13.618      0.000      -0.005      -0.003\n",
       "x10           -0.0090      0.000    -30.872      0.000      -0.010      -0.008\n",
       "x11            0.0085      0.000     27.023      0.000       0.008       0.009\n",
       "x12           -0.0136      0.000    -44.229      0.000      -0.014      -0.013\n",
       "x13           -0.0009      0.000     -2.618      0.009      -0.002      -0.000\n",
       "x14           -0.0212      0.000    -68.192      0.000      -0.022      -0.021\n",
       "x15         7.813e-06      0.000      0.022      0.983      -0.001       0.001\n",
       "x16           -0.0094      0.000    -25.967      0.000      -0.010      -0.009\n",
       "x17           -0.0138      0.000    -41.248      0.000      -0.014      -0.013\n",
       "x18           -0.0033      0.000     -8.686      0.000      -0.004      -0.003\n",
       "x19            0.0012      0.000      3.014      0.003       0.000       0.002\n",
       "x20            0.0005      0.000      1.159      0.246      -0.000       0.001\n",
       "x21            0.0056      0.000     14.058      0.000       0.005       0.006\n",
       "x22           -0.0006      0.000     -1.239      0.216      -0.001       0.000\n",
       "x23           -0.0006      0.001     -1.102      0.270      -0.002       0.000\n",
       "x24           -0.0013      0.001     -2.362      0.018      -0.002      -0.000\n",
       "x25            0.0008      0.001      1.333      0.183      -0.000       0.002\n",
       "x26            0.0004      0.001      0.568      0.570      -0.001       0.002\n",
       "x27            0.0023      0.001      2.757      0.006       0.001       0.004\n",
       "x28            0.0092      0.001      8.215      0.000       0.007       0.011\n",
       "==============================================================================\n",
       "Omnibus:                    45912.249   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         45900397.366\n",
       "Skew:                          10.323   Prob(JB):                         0.00\n",
       "Kurtosis:                     197.902   Cond. No.                         8.90\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "results = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "results.summary() \n",
    "#일단 0.5넘는 행들 다 삭제하고 다시 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =data.drop([\"V26\",\"Class\"], axis=1)\n",
    "\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979426738266267"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.640</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.639</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1884.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Aug 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:56:12</td>     <th>  Log-Likelihood:    </th>  <td>  42300.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 28678</td>      <th>  AIC:               </th> <td>-8.454e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 28650</td>      <th>  BIC:               </th> <td>-8.431e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0041</td> <td>    0.000</td> <td>   12.400</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0022</td> <td>    0.000</td> <td>  -13.120</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0025</td> <td>    0.000</td> <td>   11.521</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0061</td> <td>    0.000</td> <td>  -29.568</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0064</td> <td>    0.000</td> <td>   27.859</td> <td> 0.000</td> <td>    0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0015</td> <td>    0.000</td> <td>   -6.328</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0021</td> <td>    0.000</td> <td>   -8.465</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0048</td> <td>    0.000</td> <td>  -19.194</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0005</td> <td>    0.000</td> <td>   -2.006</td> <td> 0.045</td> <td>   -0.001</td> <td>-1.13e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0040</td> <td>    0.000</td> <td>  -13.622</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0090</td> <td>    0.000</td> <td>  -30.869</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0085</td> <td>    0.000</td> <td>   27.023</td> <td> 0.000</td> <td>    0.008</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0136</td> <td>    0.000</td> <td>  -44.239</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0009</td> <td>    0.000</td> <td>   -2.617</td> <td> 0.009</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0212</td> <td>    0.000</td> <td>  -68.198</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> 6.314e-06</td> <td>    0.000</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0094</td> <td>    0.000</td> <td>  -25.974</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0138</td> <td>    0.000</td> <td>  -41.246</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0033</td> <td>    0.000</td> <td>   -8.682</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0012</td> <td>    0.000</td> <td>    3.012</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0005</td> <td>    0.000</td> <td>    1.164</td> <td> 0.245</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0056</td> <td>    0.000</td> <td>   14.058</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0006</td> <td>    0.000</td> <td>   -1.240</td> <td> 0.215</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0006</td> <td>    0.001</td> <td>   -1.112</td> <td> 0.266</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0013</td> <td>    0.001</td> <td>   -2.362</td> <td> 0.018</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.0008</td> <td>    0.001</td> <td>    1.337</td> <td> 0.181</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0023</td> <td>    0.001</td> <td>    2.756</td> <td> 0.006</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.0092</td> <td>    0.001</td> <td>    8.215</td> <td> 0.000</td> <td>    0.007</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>45908.969</td> <th>  Durbin-Watson:     </th>   <td>   2.008</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>45888871.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.321</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>197.878</td>  <th>  Cond. No.          </th>   <td>    8.90</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &      0.640    \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.639    \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      1884.    \\\\\n",
       "\\textbf{Date:}             & Wed, 02 Aug 2023 & \\textbf{  Prob (F-statistic):} &      0.00     \\\\\n",
       "\\textbf{Time:}             &     16:56:12     & \\textbf{  Log-Likelihood:    } &     42300.    \\\\\n",
       "\\textbf{No. Observations:} &       28678      & \\textbf{  AIC:               } &  -8.454e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &       28650      & \\textbf{  BIC:               } &  -8.431e+04   \\\\\n",
       "\\textbf{Df Model:}         &          27      & \\textbf{                     } &               \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &               \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.0041  &        0.000     &    12.400  &         0.000        &        0.003    &        0.005     \\\\\n",
       "\\textbf{x1}    &      -0.0022  &        0.000     &   -13.120  &         0.000        &       -0.003    &       -0.002     \\\\\n",
       "\\textbf{x2}    &       0.0025  &        0.000     &    11.521  &         0.000        &        0.002    &        0.003     \\\\\n",
       "\\textbf{x3}    &      -0.0061  &        0.000     &   -29.568  &         0.000        &       -0.006    &       -0.006     \\\\\n",
       "\\textbf{x4}    &       0.0064  &        0.000     &    27.859  &         0.000        &        0.006    &        0.007     \\\\\n",
       "\\textbf{x5}    &      -0.0015  &        0.000     &    -6.328  &         0.000        &       -0.002    &       -0.001     \\\\\n",
       "\\textbf{x6}    &      -0.0021  &        0.000     &    -8.465  &         0.000        &       -0.003    &       -0.002     \\\\\n",
       "\\textbf{x7}    &      -0.0048  &        0.000     &   -19.194  &         0.000        &       -0.005    &       -0.004     \\\\\n",
       "\\textbf{x8}    &      -0.0005  &        0.000     &    -2.006  &         0.045        &       -0.001    &    -1.13e-05     \\\\\n",
       "\\textbf{x9}    &      -0.0040  &        0.000     &   -13.622  &         0.000        &       -0.005    &       -0.003     \\\\\n",
       "\\textbf{x10}   &      -0.0090  &        0.000     &   -30.869  &         0.000        &       -0.010    &       -0.008     \\\\\n",
       "\\textbf{x11}   &       0.0085  &        0.000     &    27.023  &         0.000        &        0.008    &        0.009     \\\\\n",
       "\\textbf{x12}   &      -0.0136  &        0.000     &   -44.239  &         0.000        &       -0.014    &       -0.013     \\\\\n",
       "\\textbf{x13}   &      -0.0009  &        0.000     &    -2.617  &         0.009        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{x14}   &      -0.0212  &        0.000     &   -68.198  &         0.000        &       -0.022    &       -0.021     \\\\\n",
       "\\textbf{x15}   &    6.314e-06  &        0.000     &     0.018  &         0.986        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{x16}   &      -0.0094  &        0.000     &   -25.974  &         0.000        &       -0.010    &       -0.009     \\\\\n",
       "\\textbf{x17}   &      -0.0138  &        0.000     &   -41.246  &         0.000        &       -0.014    &       -0.013     \\\\\n",
       "\\textbf{x18}   &      -0.0033  &        0.000     &    -8.682  &         0.000        &       -0.004    &       -0.003     \\\\\n",
       "\\textbf{x19}   &       0.0012  &        0.000     &     3.012  &         0.003        &        0.000    &        0.002     \\\\\n",
       "\\textbf{x20}   &       0.0005  &        0.000     &     1.164  &         0.245        &       -0.000    &        0.001     \\\\\n",
       "\\textbf{x21}   &       0.0056  &        0.000     &    14.058  &         0.000        &        0.005    &        0.006     \\\\\n",
       "\\textbf{x22}   &      -0.0006  &        0.000     &    -1.240  &         0.215        &       -0.001    &        0.000     \\\\\n",
       "\\textbf{x23}   &      -0.0006  &        0.001     &    -1.112  &         0.266        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{x24}   &      -0.0013  &        0.001     &    -2.362  &         0.018        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{x25}   &       0.0008  &        0.001     &     1.337  &         0.181        &       -0.000    &        0.002     \\\\\n",
       "\\textbf{x26}   &       0.0023  &        0.001     &     2.756  &         0.006        &        0.001    &        0.004     \\\\\n",
       "\\textbf{x27}   &       0.0092  &        0.001     &     8.215  &         0.000        &        0.007    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 45908.969 & \\textbf{  Durbin-Watson:     } &      2.008    \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 45888871.104  \\\\\n",
       "\\textbf{Skew:}          &   10.321  & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
       "\\textbf{Kurtosis:}      &  197.878  & \\textbf{  Cond. No.          } &       8.90    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.640\n",
       "Model:                            OLS   Adj. R-squared:                  0.639\n",
       "Method:                 Least Squares   F-statistic:                     1884.\n",
       "Date:                Wed, 02 Aug 2023   Prob (F-statistic):               0.00\n",
       "Time:                        16:56:12   Log-Likelihood:                 42300.\n",
       "No. Observations:               28678   AIC:                        -8.454e+04\n",
       "Df Residuals:                   28650   BIC:                        -8.431e+04\n",
       "Df Model:                          27                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0041      0.000     12.400      0.000       0.003       0.005\n",
       "x1            -0.0022      0.000    -13.120      0.000      -0.003      -0.002\n",
       "x2             0.0025      0.000     11.521      0.000       0.002       0.003\n",
       "x3            -0.0061      0.000    -29.568      0.000      -0.006      -0.006\n",
       "x4             0.0064      0.000     27.859      0.000       0.006       0.007\n",
       "x5            -0.0015      0.000     -6.328      0.000      -0.002      -0.001\n",
       "x6            -0.0021      0.000     -8.465      0.000      -0.003      -0.002\n",
       "x7            -0.0048      0.000    -19.194      0.000      -0.005      -0.004\n",
       "x8            -0.0005      0.000     -2.006      0.045      -0.001   -1.13e-05\n",
       "x9            -0.0040      0.000    -13.622      0.000      -0.005      -0.003\n",
       "x10           -0.0090      0.000    -30.869      0.000      -0.010      -0.008\n",
       "x11            0.0085      0.000     27.023      0.000       0.008       0.009\n",
       "x12           -0.0136      0.000    -44.239      0.000      -0.014      -0.013\n",
       "x13           -0.0009      0.000     -2.617      0.009      -0.002      -0.000\n",
       "x14           -0.0212      0.000    -68.198      0.000      -0.022      -0.021\n",
       "x15         6.314e-06      0.000      0.018      0.986      -0.001       0.001\n",
       "x16           -0.0094      0.000    -25.974      0.000      -0.010      -0.009\n",
       "x17           -0.0138      0.000    -41.246      0.000      -0.014      -0.013\n",
       "x18           -0.0033      0.000     -8.682      0.000      -0.004      -0.003\n",
       "x19            0.0012      0.000      3.012      0.003       0.000       0.002\n",
       "x20            0.0005      0.000      1.164      0.245      -0.000       0.001\n",
       "x21            0.0056      0.000     14.058      0.000       0.005       0.006\n",
       "x22           -0.0006      0.000     -1.240      0.215      -0.001       0.000\n",
       "x23           -0.0006      0.001     -1.112      0.266      -0.002       0.000\n",
       "x24           -0.0013      0.001     -2.362      0.018      -0.002      -0.000\n",
       "x25            0.0008      0.001      1.337      0.181      -0.000       0.002\n",
       "x26            0.0023      0.001      2.756      0.006       0.001       0.004\n",
       "x27            0.0092      0.001      8.215      0.000       0.007       0.011\n",
       "==============================================================================\n",
       "Omnibus:                    45908.969   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         45888871.104\n",
       "Skew:                          10.321   Prob(JB):                         0.00\n",
       "Kurtosis:                     197.878   Cond. No.                         8.90\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "results = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "results.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Actual')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(X)\n",
    "cm = confusion_matrix(y, pred)\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 20}, cmap='YlOrBr')\n",
    "plt.xlabel('Predicted', fontsize=20)\n",
    "plt.ylabel('Actual', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28423, 9, 50, 196)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=LogisticRegression(thres)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regression_과제3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
